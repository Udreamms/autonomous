import { NextResponse } from 'next/server';
import { GoogleGenerativeAI } from "@google/generative-ai";
import Anthropic from '@anthropic-ai/sdk';
import OpenAI from 'openai';
import fs from 'fs';
import path from 'path';
import { SYSTEM_PROMPT } from './prompt';

const REFINE_PROMPT = `
You are an Elite UI/UX Design Critic. Your job is to review the code generated by another AI and perform a "Design Pass" to make it look professional and premium.

CHECKLIST:
1. ANIMATIONS: Ensure EVERY section has a 'framer-motion' reveal. Add entrance animations if missing.
2. DESIGN TOKENS: Ensure it uses 'text-primary', 'shadow-premium', 'rounded-2xl'. Fix generic CSS.
3. RESPONSIVENESS: Check for 'md:' and 'lg:' prefixes in grids and padding.
4. POLISH: Add subtle 'animate-float' to hero assets.
5. IMAGE AUDIT (CRITICAL):
   - Replace any 'src=""', 'src="#"', or local '/assets/...' paths that don't exist in the project with a high-quality Unsplash image from Section 8 of the systemic prompt.
   - Every <img> must have a valid, external 'src'.

RULES:
- ONLY RETURN the fixed code in 'code_update' format.
- DO NOT change the functionality, only the UI/UX aesthetics.
- REQUIRED: RETURN THE FULL FILE CONTENT. DO NOT USE PLACEHOLDERS LIKE '// ... rest of code' OR '// ... existing code'.
- IF YOU MODIFY A FILE, YOU MUST RETURN THE ENTIRE FILE.
- Be surgical but COMPLETE.
`;

function logToFile(msg: string) {
  try {
    const logPath = path.join(process.cwd(), 'ai-route.log');
    const timestamp = new Date().toISOString();
    fs.appendFileSync(logPath, `[${timestamp}] ${msg}\n`);
  } catch (e) {
    console.error('Logging failed', e);
  }
}

// Lazy AI clients
let genAI: any = null;
let anthropic: any = null;
let openai: any = null;

function getGenAI() {
  if (!genAI && process.env.GEMINI_API_KEY) {
    genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);
  }
  return genAI;
}

function getAnthropic() {
  if (!anthropic && process.env.ANTHROPIC_API_KEY) {
    anthropic = new Anthropic({ apiKey: process.env.ANTHROPIC_API_KEY });
  }
  return anthropic;
}

function getOpenAI() {
  if (!openai && process.env.OPENAI_API_KEY) {
    openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
  }
  return openai;
}

function getProvider(modelName: string): 'gemini' | 'anthropic' | 'openai' {
  if (modelName.includes('Claude')) return 'anthropic';
  if (modelName.includes('GPT')) return 'openai';
  return 'gemini';
}

async function callGemini(modelName: string, messages: any[], fileContext: string, attemptIdx = 0): Promise<string> {
  const client = getGenAI();
  if (!client) throw new Error("Gemini API not initialized.");

  // List of models to try for each type
  const proModels = ["gemini-2.0-pro-exp-02-05", "gemini-1.5-pro-002", "gemini-1.5-pro-latest", "gemini-1.5-pro", "gemini-2.0-flash"];
  const flashModels = ["gemini-2.0-flash", "gemini-1.5-flash-002", "gemini-1.5-flash"];

  let candidates = flashModels;
  if (modelName.toLowerCase().includes("pro") || modelName.includes("3.0")) {
    candidates = proModels;
  }

  // Ensure we don't exceed the list
  const currentModelId = candidates[Math.min(attemptIdx, candidates.length - 1)];

  logToFile(`[callGemini] Attempt ${attemptIdx} using ID: ${currentModelId}`);
  console.log(`[callGemini] Attempt ${attemptIdx} using ID: ${currentModelId}`);

  try {
    const history = [
      { role: "user", parts: [{ text: SYSTEM_PROMPT }] },
      { role: "model", parts: [{ text: JSON.stringify({ type: "message", content: "Ready." }) }] }
    ];

    if (messages && messages.length > 1) {
      messages.slice(0, -1).forEach(msg => {
        history.push({
          role: msg.role === 'ai' || msg.role === 'model' ? 'model' : 'user',
          parts: [{ text: typeof msg.content === 'string' ? msg.content : JSON.stringify(msg.content) }]
        });
      });
    }

    const model = client.getGenerativeModel({ model: currentModelId });
    const chat = model.startChat({ history, generationConfig: { responseMimeType: "application/json" } });
    const result = await chat.sendMessage([{ text: messages[messages.length - 1].content + fileContext }]);
    return result.response.text();
  } catch (error: any) {
    const isNotFoundError = error.message?.includes('404') || error.status === 404 || error.message?.includes('not found');

    if (isNotFoundError && attemptIdx < candidates.length - 1) {
      logToFile(`[callGemini] Model ${currentModelId} 404'd. Falling back to next...`);
      return callGemini(modelName, messages, fileContext, attemptIdx + 1);
    }
    throw error;
  }
}

async function callClaude(modelName: string, messages: any[], fileContext: string) {
  const client = getAnthropic();
  if (!client) throw new Error("Anthropic API not initialized.");
  const claudeMsgs = messages.map(msg => ({
    role: msg.role === 'ai' || msg.role === 'model' ? 'assistant' : 'user',
    content: typeof msg.content === 'string' ? msg.content : JSON.stringify(msg.content)
  }));
  if (fileContext) claudeMsgs[claudeMsgs.length - 1].content += fileContext;
  const res = await client.messages.create({
    model: "claude-3-5-sonnet-20241022",
    max_tokens: 8192,
    system: SYSTEM_PROMPT,
    messages: claudeMsgs as any
  });
  return (res.content[0] as any).text;
}

async function callOpenAI(modelName: string, messages: any[], fileContext: string) {
  const client = getOpenAI();
  if (!client) throw new Error("OpenAI API not initialized.");
  const openMsgs = [
    { role: "system", content: SYSTEM_PROMPT },
    ...messages.map(msg => ({
      role: msg.role === 'ai' || msg.role === 'model' ? 'assistant' : 'user',
      content: typeof msg.content === 'string' ? msg.content : JSON.stringify(msg.content)
    }))
  ];
  if (fileContext) openMsgs[openMsgs.length - 1].content += fileContext;
  const res = await client.chat.completions.create({
    model: "gpt-4o",
    messages: openMsgs as any,
    response_format: { type: "json_object" }
  });
  return res.choices[0].message.content || "";
}

function extractJSON(responseText: string) {
  let cleaned = responseText.trim();
  try {
    // 1. Remove Markdown code blocks if they exist
    if (cleaned.includes('```')) {
      const firstBrace = cleaned.indexOf('{');
      const lastBrace = cleaned.lastIndexOf('}');
      if (firstBrace !== -1 && lastBrace !== -1) {
        cleaned = cleaned.substring(firstBrace, lastBrace + 1);
      }
    }

    // 2. Remove potential leading/trailing non-JSON text
    const start = cleaned.indexOf('{');
    const end = cleaned.lastIndexOf('}');
    if (start !== -1 && end !== -1) {
      cleaned = cleaned.substring(start, end + 1);
    }

    try {
      return JSON.parse(cleaned);
    } catch (parseError) {
      // 3. Fallback: Try to escape literal newlines inside string values
      // This is a common AI error where it puts actual newlines instead of \n
      const fixed = cleaned.replace(/: "([\s\S]*?)"/g, (match, p1) => {
        return `: "${p1.replace(/\n/g, '\\n')}"`;
      });
      return JSON.parse(fixed);
    }
  } catch (e: any) {
    logToFile(`[extractJSON] Parse failed: ${e.message}. Raw prefix: ${responseText.substring(0, 200)}...`);

    // Emergency regex extraction for common AI mistakes
    try {
      const jsonMatch = responseText.match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        const raw = jsonMatch[0];
        const fixed = raw.replace(/: "([\s\S]*?)"/g, (match, p1) => {
          return `: "${p1.replace(/\n/g, '\\n')}"`;
        });
        return JSON.parse(fixed);
      }
    } catch (e2) { }

    return { type: "message", content: "Error: La IA devolvi√≥ un formato inv√°lido. Por favor, intenta reformular tu solicitud." };
  }
}

async function callAI(provider: 'gemini' | 'anthropic' | 'openai', modelName: string, messages: any[], fileContext: string, retryCount = 0): Promise<any> {
  const startTime = Date.now();
  logToFile(`[AI Request] Provider: ${provider}, Model: ${modelName}, Retry: ${retryCount}`);

  try {
    let responseText = "";
    switch (provider) {
      case 'gemini': responseText = await callGemini(modelName, messages, fileContext); break;
      case 'anthropic': responseText = await callClaude(modelName, messages, fileContext); break;
      case 'openai': responseText = await callOpenAI(modelName, messages, fileContext); break;
    }

    logToFile(`[AI Response] Received in ${Date.now() - startTime}ms`);
    return extractJSON(responseText);
  } catch (error: any) {
    const isRateLimit = error.message?.includes('429') || error.status === 429;
    const isServerError = error.message?.includes('500') || error.status === 500;

    logToFile(`[AI Error] ${error.message} (RateLimit: ${isRateLimit}, ServerError: ${isServerError})`);

    if ((isRateLimit || isServerError) && retryCount < 3) {
      const waitTime = Math.pow(2, retryCount) * 1000;
      logToFile(`[AI Retry] Waiting ${waitTime}ms before retry ${retryCount + 1}`);
      await new Promise(r => setTimeout(r, waitTime));
      return callAI(provider, modelName, messages, fileContext, retryCount + 1);
    }
    throw error;
  }
}

function validateAndFixJSX(code: string, filePath: string): string {
  if (filePath.endsWith('.tsx') || filePath.endsWith('.jsx')) {
    // Self-Heal: Fix Default Imports for Shadcn Components (Common AI Error)
    // The AI often does `import Card from ...` but it should be `import { Card } from ...`
    const componentsToFix = ['Card', 'Input', 'Button', 'Badge', 'Label', 'Switch', 'Slider', 'Table', 'Avatar', 'Dialog', 'Sheet', 'Textarea', 'RadioGroup', 'Checkbox', 'Select', 'Tabs'];
    componentsToFix.forEach(comp => {
      // Case 1: Simple default import: `import Card from "@/..."` OR `import Card from "../..."`
      // We match paths starting with @/, ./, or ../ 
      const defaultImportRegex = new RegExp(`import\\s+${comp}\\s+from\\s+['"]((?:@\\/|\\.\\/|\\.\\.\\/)[^'"]+)['"]`, 'g');
      code = code.replace(defaultImportRegex, `import { ${comp} } from "$1"`);

      // Case 2: Mixed import (same path rules)
      const mixedImportRegex = new RegExp(`import\\s+${comp}\\s*,\\s*\\{\\s*([^}]+)\\s*\\}\\s+from\\s+['"]((?:@\\/|\\.\\/|\\.\\.\\/)[^'"]+)['"]`, 'g');
      code = code.replace(mixedImportRegex, `import { ${comp}, $1 } from "$2"`);
    });

    // Self-Heal: FORCE HashRouter (Super Aggressive)
    // 1. Handle aliased imports: import { BrowserRouter as Router } -> import { HashRouter as Router }
    if (code.includes('BrowserRouter as Router')) {
      code = code.replace(/BrowserRouter as Router/g, 'HashRouter as Router');
    }

    // 2. Handle standard imports and usage
    if (code.includes('BrowserRouter')) {
      code = code.replace(/BrowserRouter/g, 'HashRouter');
    }

    // 3. Fix imports: Ensure HashRouter is imported from 'react-router-dom'
    if (code.includes('HashRouter') && !code.includes('import { HashRouter')) {
      // If there's an existing react-router-dom import, append HashRouter
      if (code.includes("from 'react-router-dom'") || code.includes('from "react-router-dom"')) {
        // Use a more flexible regex to capture the import block
        code = code.replace(/import\s*{([^}]+)}\s*from\s*['"]react-router-dom['"]/, (match, content) => {
          if (content.includes('HashRouter')) return match; // Already there
          return `import { ${content}, HashRouter } from "react-router-dom"`;
        });
      } else {
        // Otherwise add it to the top
        code = "import { HashRouter } from 'react-router-dom';\n" + code;
      }
    }

    // 4. Clean up duplicate imports & messy syntax
    code = code.replace(/HashRouter\s*,\s*HashRouter/g, 'HashRouter');
    code = code.replace(/,\s*}/g, ' }');
    // Fix potential "import { HashRouter as Router, HashRouter }" mess
    code = code.replace(/HashRouter as Router,\s*HashRouter/g, 'HashRouter as Router');

    // Self-Heal: Fix Lucide Icon Imports
    code = code.replace(/import\s+([A-Z][a-zA-Z0-9]*)\s+from\s+['"]lucide-react['"]/g, 'import { $1 } from "lucide-react"');

    console.log(`[Self-Heal] Fixed import code for ${filePath}`);

    // Self-Heal: Ensure buttonVariants is imported if used but missing from imports
    if (code.includes('buttonVariants(') && !code.includes('buttonVariants')) {
      // Look for any import from a path ending in /button
      const buttonImportRegex = /import\s*\{\s*Button\s*\}\s*from\s*["']([^"']+\/button)["']/;
      const match = code.match(buttonImportRegex);
      if (match) {
        const path = match[1];
        code = code.replace(
          new RegExp(`import\\s*\\{\\s*Button\\s*\\}\\s*from\\s*["']${path}["']`),
          `import { Button, buttonVariants } from "${path}"`
        );
      }
    }



  }
  return code;
}

export async function GET() {
  return NextResponse.json({ status: "ok", time: new Date().toISOString() });
}

export async function POST(req: Request) {
  const startTimestamp = Date.now();
  const requestId = Math.random().toString(36).substring(7);
  logToFile(`[POST] [${requestId}] Started`);

  try {
    const { messages, currentFiles, model } = await req.json();

    // Intelligent Context: Filter large files or irrelevant assets to prevent context bloat
    const fileEntries = Object.entries(currentFiles || {}) as [string, string][];
    const filteredFiles = fileEntries.filter(([path]) => {
      const isAsset = path.includes('/assets/') || path.includes('/public/') || path.endsWith('.png') || path.endsWith('.jpg') || path.endsWith('.svg');
      return !isAsset;
    });

    const fileContext = filteredFiles.length > 0 ? "\n\nCODE CONTEXT:\n" + filteredFiles
      .map(([p, c]) => `--- FILE: ${p} ---\n${c}\n`)
      .join("\n")
      .substring(0, 50000) : ""; // Increased to 50k for more project awareness

    let selectedModel = model || "Gemini 2.0 Flash";

    // --- AUTO-DETECT FRESH PROJECT (FORCE GEMINI 3.0) ---
    // If App.tsx contains the placeholder text, we assume it's a new project.
    // User wants Gemini 3.0 Pro for the FIRST generation.
    const appFileContent = currentFiles?.["src/App.tsx"] || "";
    if (appFileContent.includes("Waiting for instructions...")) {
      logToFile("[Model Override] Fresh project detected! Forcing usage of Gemini 3.0 (Preview) for initial scaffolding.");
      selectedModel = "Gemini 3.0 (Preview)";
    }

    // --- HELPER TO CLEAN AND INJECT MAIN.TSX ---
    const processAIResult = (aiResult: any) => {
      if (aiResult.type === 'code_update' && aiResult.files) {
        aiResult.files = aiResult.files.map((file: any) => ({
          ...file,
          content: file.path.endsWith('.tsx') ? validateAndFixJSX(file.content, file.path) : file.content
        }));

        // --- DYNAMICALLY FIND APP.TSX PATH ---
        // The AI might put App.tsx in src/ or src/pages/ or elsewhere.
        // We find it to ensure the import in main.tsx is correct.
        let appPath = './App.tsx';
        const foundAppFile = aiResult.files.find((f: any) =>
          f.path.toLowerCase().endsWith('app.tsx') || f.path.toLowerCase().endsWith('app.jsx')
        );

        if (foundAppFile) {
          // Calculate relative path from src/main.tsx to the found App file.
          // Since main.tsx is always in src/, and the file path is 'src/...'
          const fullPath = foundAppFile.path; // e.g. "src/pages/App.tsx"
          if (fullPath.startsWith('src/')) {
            const relativePart = fullPath.replace('src/', './'); // e.g. "./pages/App.tsx"
            appPath = relativePart.replace(/\.(tsx|jsx)$/, ''); // e.g. "./pages/App"
          }
        }

        const CLEAN_MAIN_TSX = `import React from 'react'
import ReactDOM from 'react-dom/client'
import App from '${appPath}'
import './index.css'

class ErrorBoundary extends React.Component<{ children: React.ReactNode }, { hasError: boolean, error: Error | null, errorInfo: React.ErrorInfo | null }> {
  constructor(props: { children: React.ReactNode }) {
    super(props);
    this.state = { hasError: false, error: null, errorInfo: null };
  }

  static getDerivedStateFromError(error: any) {
    const normalizedError = error instanceof Error ? error : new Error(String(error || "Unknown Error Event"));
    return { hasError: true, error: normalizedError };
  }

  componentDidCatch(error: any, errorInfo: React.ErrorInfo) {
    console.error("Uncaught error:", error, errorInfo);
    this.setState({ errorInfo, error: error instanceof Error ? error : new Error(JSON.stringify(error)) });
  }

  render() {
    if (this.state.hasError) {
      return (
        <div className="min-h-screen bg-black text-white p-8 flex flex-col items-center justify-center font-sans">
          <div className="max-w-2xl w-full bg-red-950/30 border border-red-500/50 rounded-xl p-6 shadow-2xl">
            <h2 className="text-2xl font-bold text-red-500 mb-4 flex items-center gap-2"><span>‚ö†Ô∏è</span> Application Crashed</h2>
            <div className="bg-black/50 p-4 rounded-lg overflow-auto max-h-[60vh] border border-red-500/20">
              <p className="text-red-200 font-mono text-sm mb-4 font-bold">{this.state.error?.message || "Unknown Error"}</p>
              {this.state.errorInfo && <pre className="text-red-400/70 text-xs font-mono whitespace-pre-wrap">{this.state.errorInfo.componentStack}</pre>}
            </div>
            <button onClick={() => window.location.reload()} className="mt-6 px-4 py-2 bg-red-600 hover:bg-red-700 text-white rounded-lg transition-colors text-sm font-medium">Reload Preview</button>
          </div>
        </div>
      );
    }
    return this.props.children; 
  }
}

ReactDOM.createRoot(document.getElementById('root')!).render(
  <React.StrictMode>
    <ErrorBoundary>
      <App />
    </ErrorBoundary>
  </React.StrictMode>,
)`;
        aiResult.files = aiResult.files.filter((f: any) => f.path !== 'src/main.tsx' && f.path !== 'src/index.tsx');
        aiResult.files.push({ path: 'src/main.tsx', content: CLEAN_MAIN_TSX });
      }
      return aiResult;
    };

    // Multi-AI Consensus Mode (Restored with 2.0+ models)
    if (selectedModel === 'Multi-AI (Consensus)') {
      try {
        logToFile(`[Multi-AI] Starting consensus flow using Gemini 3.0 (Pro Exp)...`);

        // As per user request: "mutiIA genere codigo con gemini 3.0pro"
        // We map "Gemini 3.0 Pro" to our best available model: gemini-2.0-pro-exp-02-05
        const CONSENSUS_MODEL = "gemini-2.0-pro-exp-02-05";

        const plan = await callAI('gemini', CONSENSUS_MODEL, [{ role: 'user', content: "Plan: " + messages[messages.length - 1].content }], fileContext);
        const build = await callAI('gemini', CONSENSUS_MODEL, [{ role: 'user', content: "Build: " + JSON.stringify(plan) }], fileContext);
        const final = await callAI('gemini', CONSENSUS_MODEL, [{ role: 'user', content: "Refine: " + JSON.stringify(build) }], fileContext);

        logToFile(`[Multi-AI] Consensus completed in ${Date.now() - startTimestamp}ms`);

        // Apply processed result to Multi-AI flow
        const finalProcessed = processAIResult(final);
        return NextResponse.json({ ...finalProcessed, content: "üöÄ Multi-AI Consensus Success (Powered by Gemini 2.0 Pro)", plan });
      } catch (e: any) {
        logToFile(`[Multi-AI Error] ${e.message}. Falling back to single AI.`);
        const fallback = await callAI('gemini', "gemini-2.0-pro-exp-02-05", messages, fileContext);
        return NextResponse.json(processAIResult(fallback));
      }
    }

    let result = await callAI(getProvider(selectedModel), selectedModel, messages, fileContext);

    // --- AGENTIC REFINEMENT (Step 4: Design Pass) ---
    // Perform a second pass for deep design polish if it's a code update and not already a refinement
    if (result.type === 'code_update' && result.files && result.files.length > 0) {
      logToFile(`[Refinement] Starting Design Pass...`);
      try {
        const refinementResult = await callAI('gemini', "Gemini 2.0 Flash", [
          { role: 'system', content: REFINE_PROMPT },
          { role: 'user', content: `REVIEW AND POLISH THIS CODE:\n\n${JSON.stringify(result.files)}` }
        ], ""); // No extra context needed for polish

        if (refinementResult.type === 'code_update' && refinementResult.files) {
          logToFile(`[Refinement] Design Pass completed successfully.`);
          result.files = refinementResult.files;
          result.content = "‚ú® Ultra Polish Applied: " + result.content;
        }
      } catch (refineError: any) {
        logToFile(`[Refinement Error] Failed to refine, returning original: ${refineError.message}`);
      }
    }

    if (result.type === 'code_update' && result.files) {
      result.files = result.files.map((file: any) => ({
        ...file,
        content: file.path.endsWith('.tsx') ? validateAndFixJSX(file.content, file.path) : file.content
      }));
    }

    result = processAIResult(result);

    logToFile(`[POST] [${requestId}] Completed in ${Date.now() - startTimestamp}ms`);
    return NextResponse.json(result);
  } catch (e: any) {
    logToFile(`[POST Error] [${requestId}] ${e.message}`);

    let userMessage = "Error: " + e.message;
    if (e.message?.includes('429') || e.status === 429) {
      userMessage = "La IA est√° procesando demasiadas solicitudes en este momento. Por favor, espera unos segundos e intenta de nuevo.";
    } else if (e.message?.includes('500')) {
      userMessage = "Hubo un problema temporal con el servidor de la IA. Por favor, intenta de nuevo en un momento.";
    }

    return NextResponse.json({ type: "message", content: userMessage }, { status: 500 });
  }
}
